<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>传智播客--六节爬虫课 | Jacky's blogs</title><meta name="description" content="传智播客--六节爬虫课"><meta name="keywords" content="爬虫"><meta name="author" content="Jacky"><meta name="copyright" content="Jacky"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="https://wangjs-jacky.github.io/2019/12/09/%E4%BC%A0%E4%BC%A0%E6%99%BA%E6%92%AD%E5%AE%A2_%E5%85%AD%E8%8A%82%E7%88%AC%E8%99%AB%E8%AF%BE/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="传智播客--六节爬虫课"><meta name="twitter:description" content="传智播客--六节爬虫课"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/爬虫.png"><meta property="og:type" content="article"><meta property="og:title" content="传智播客--六节爬虫课"><meta property="og:url" content="https://wangjs-jacky.github.io/2019/12/09/%E4%BC%A0%E4%BC%A0%E6%99%BA%E6%92%AD%E5%AE%A2_%E5%85%AD%E8%8A%82%E7%88%AC%E8%99%AB%E8%AF%BE/"><meta property="og:site_name" content="Jacky's blogs"><meta property="og:description" content="传智播客--六节爬虫课"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/爬虫.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="prev" title="论文模板设置" href="https://wangjs-jacky.github.io/2019/12/09/%E8%AE%BA%E6%96%87%E6%A8%A1%E6%9D%BF%E8%AE%BE%E7%BD%AE/"><link rel="next" title="实用网站收集" href="https://wangjs-jacky.github.io/2019/12/04/%E5%AE%9E%E7%94%A8%E7%BD%91%E7%AB%99%E6%94%B6%E9%9B%86/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: '添加书签',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  copyright: undefined,
  copy_copyright_js: false
  
}</script></head><body><canvas class="fireworks"></canvas><div id="header"> <div id="page-header"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Jacky's blogs</a></span><i class="fa fa-bars fa-fw toggle-menu pull-right close" aria-hidden="true"></i><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/categories/SklearnAPI"><i class="fa-fw fa fa-music"></i><span> SklearnAPI</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 列表</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lozad avatar_img" src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/小李.jpg" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">55</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">22</div></a></div></div><div class="mobile_data_item is_center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">55</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/categories/SklearnAPI"><i class="fa-fw fa fa-music"></i><span> SklearnAPI</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 列表</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#爬虫概念-工具和http"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text"> 爬虫概念、工具和HTTP</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#什么是爬虫"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text"> 什么是爬虫</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#爬虫的数据的应用"><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text"> 爬虫的数据的应用</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#需要的软件和环境"><span class="toc_mobile_items-number">1.3.</span> <span class="toc_mobile_items-text"> 需要的软件和环境</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#浏览器的请求"><span class="toc_mobile_items-number">1.4.</span> <span class="toc_mobile_items-text"> 浏览器的请求</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#认识http-https"><span class="toc_mobile_items-number">1.5.</span> <span class="toc_mobile_items-text"> 认识HTTP、HTTPS</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#requests-模块的学习"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text"> requests 模块的学习</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#使用前安装"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text"> 使用前：安装</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#发送getpost请求获取响应"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text"> 发送get,post请求，获取响应</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#response的方法"><span class="toc_mobile_items-number">2.3.</span> <span class="toc_mobile_items-text"> response的方法</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#获取网页源码的正确打开方式"><span class="toc_mobile_items-number">2.4.</span> <span class="toc_mobile_items-text"> 获取网页源码的正确打开方式</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#发送带header的请求"><span class="toc_mobile_items-number">2.5.</span> <span class="toc_mobile_items-text"> 发送带header的请求</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#使用超时参数"><span class="toc_mobile_items-number">2.6.</span> <span class="toc_mobile_items-text"> 使用超时参数</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#retrying-模块的学习"><span class="toc_mobile_items-number">2.7.</span> <span class="toc_mobile_items-text"> retrying 模块的学习</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#处理cookie相关的请求"><span class="toc_mobile_items-number">2.8.</span> <span class="toc_mobile_items-text"> 处理Cookie相关的请求</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#️数据提取方法"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text"> ⭐️数据提取方法</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#json格式介绍"><span class="toc_mobile_items-number">3.1.</span> <span class="toc_mobile_items-text"> json格式介绍</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#json语法介绍"><span class="toc_mobile_items-number">3.1.1.</span> <span class="toc_mobile_items-text"> Json语法介绍</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#jsonloads"><span class="toc_mobile_items-number">3.1.1.1.</span> <span class="toc_mobile_items-text"> json.loads</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#jsondumps"><span class="toc_mobile_items-number">3.1.1.2.</span> <span class="toc_mobile_items-text"> json.dumps</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#案例豆瓣获取美剧分类爬虫案例"><span class="toc_mobile_items-number">3.1.2.</span> <span class="toc_mobile_items-text"> 案例：豆瓣获取美剧分类爬虫案例</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#xpath-和-lxml"><span class="toc_mobile_items-number">3.2.</span> <span class="toc_mobile_items-text"> Xpath 和 lxml</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#xpath语法"><span class="toc_mobile_items-number">3.2.1.</span> <span class="toc_mobile_items-text"> xpath语法</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#爬虫实例获取某瓣的标题url图片地址评论数评分等信息"><span class="toc_mobile_items-number">3.2.2.</span> <span class="toc_mobile_items-text"> 爬虫实例：获取某瓣的标题，url，图片地址，评论数，评分等信息</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#基础知识点的学习"><span class="toc_mobile_items-number">3.2.3.</span> <span class="toc_mobile_items-text"> 基础知识点的学习</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#最终案例"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text"> 最终案例</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#写爬虫的讨论"><span class="toc_mobile_items-number">4.0.1.</span> <span class="toc_mobile_items-text"> 写爬虫的讨论</span></a></li></ol></li></ol></li></ol></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#爬虫概念-工具和http"><span class="toc-number">1.</span> <span class="toc-text"> 爬虫概念、工具和HTTP</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是爬虫"><span class="toc-number">1.1.</span> <span class="toc-text"> 什么是爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#爬虫的数据的应用"><span class="toc-number">1.2.</span> <span class="toc-text"> 爬虫的数据的应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#需要的软件和环境"><span class="toc-number">1.3.</span> <span class="toc-text"> 需要的软件和环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#浏览器的请求"><span class="toc-number">1.4.</span> <span class="toc-text"> 浏览器的请求</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#认识http-https"><span class="toc-number">1.5.</span> <span class="toc-text"> 认识HTTP、HTTPS</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#requests-模块的学习"><span class="toc-number">2.</span> <span class="toc-text"> requests 模块的学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#使用前安装"><span class="toc-number">2.1.</span> <span class="toc-text"> 使用前：安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#发送getpost请求获取响应"><span class="toc-number">2.2.</span> <span class="toc-text"> 发送get,post请求，获取响应</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#response的方法"><span class="toc-number">2.3.</span> <span class="toc-text"> response的方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#获取网页源码的正确打开方式"><span class="toc-number">2.4.</span> <span class="toc-text"> 获取网页源码的正确打开方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#发送带header的请求"><span class="toc-number">2.5.</span> <span class="toc-text"> 发送带header的请求</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用超时参数"><span class="toc-number">2.6.</span> <span class="toc-text"> 使用超时参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#retrying-模块的学习"><span class="toc-number">2.7.</span> <span class="toc-text"> retrying 模块的学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#处理cookie相关的请求"><span class="toc-number">2.8.</span> <span class="toc-text"> 处理Cookie相关的请求</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#️数据提取方法"><span class="toc-number">3.</span> <span class="toc-text"> ⭐️数据提取方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#json格式介绍"><span class="toc-number">3.1.</span> <span class="toc-text"> json格式介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#json语法介绍"><span class="toc-number">3.1.1.</span> <span class="toc-text"> Json语法介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#jsonloads"><span class="toc-number">3.1.1.1.</span> <span class="toc-text"> json.loads</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#jsondumps"><span class="toc-number">3.1.1.2.</span> <span class="toc-text"> json.dumps</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#案例豆瓣获取美剧分类爬虫案例"><span class="toc-number">3.1.2.</span> <span class="toc-text"> 案例：豆瓣获取美剧分类爬虫案例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#xpath-和-lxml"><span class="toc-number">3.2.</span> <span class="toc-text"> Xpath 和 lxml</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#xpath语法"><span class="toc-number">3.2.1.</span> <span class="toc-text"> xpath语法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#爬虫实例获取某瓣的标题url图片地址评论数评分等信息"><span class="toc-number">3.2.2.</span> <span class="toc-text"> 爬虫实例：获取某瓣的标题，url，图片地址，评论数，评分等信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基础知识点的学习"><span class="toc-number">3.2.3.</span> <span class="toc-text"> 基础知识点的学习</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#最终案例"><span class="toc-number">4.</span> <span class="toc-text"> 最终案例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#写爬虫的讨论"><span class="toc-number">4.0.1.</span> <span class="toc-text"> 写爬虫的讨论</span></a></li></ol></li></ol></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/爬虫.png)"><div id="post-info"><div id="post-title"><div class="posttitle">传智播客--六节爬虫课</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-12-09<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-01-17</time><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">3.1k</span><span class="post-meta__separator">|</span><span>阅读时长: 12 分钟</span><span class="post-meta__separator">|</span><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="爬虫概念-工具和http"><a class="markdownIt-Anchor" href="#爬虫概念-工具和http"></a> 爬虫概念、工具和HTTP</h1>
<h2 id="什么是爬虫"><a class="markdownIt-Anchor" href="#什么是爬虫"></a> 什么是爬虫</h2>
<ul>
<li>爬虫就是<code>模拟客户端(游览器)发送网络请求</code>，获取相应，按照规则提取数据的程序。</li>
<li><code>模拟哭护短(浏览器)发送网络请求</code>：照着浏览器发送一模一样的请求，获取和浏览器一模一样的数据。</li>
</ul>
<h2 id="爬虫的数据的应用"><a class="markdownIt-Anchor" href="#爬虫的数据的应用"></a> 爬虫的数据的应用</h2>
<ul>
<li>呈现出来：展示在网页上，或者是展示在app上</li>
<li>进行分析：从数据中寻找一些规律</li>
</ul>
<h2 id="需要的软件和环境"><a class="markdownIt-Anchor" href="#需要的软件和环境"></a> 需要的软件和环境</h2>
<ul>
<li>
<p>python3</p>
<ul>
<li>黑马python基础班15天视频
<ol>
<li>基础语法（字符串，列表，字典，判断和循环）</li>
<li>函数（函数的创建和调用）</li>
<li>面向对象（如何创建一个类，如何使用这个类）</li>
</ol>
</li>
</ul>
</li>
<li>
<p>chrome</p>
<ul>
<li>分析网络请求用的</li>
</ul>
</li>
</ul>
<h2 id="浏览器的请求"><a class="markdownIt-Anchor" href="#浏览器的请求"></a> 浏览器的请求</h2>
<ul>
<li>
<p>url</p>
<ul>
<li>
<p>在chrome中点击检查，点击network</p>
</li>
<li>
<p>url = 请求的协议（http）+  网站的域名 + 资源的路径 + 参数(?开头&amp;隔开)</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https://www.baidu.com/s?ie=utf-8&amp;f=8&amp;rsv_bp=1&amp;rsv_idx=2&amp;ch=&amp;tn=baiduhome_pg&amp;bar=&amp;wd=abc&amp;rsv_spt=1&amp;oq=abc&amp;rsv_pq=be41b8270005d8a9&amp;rsv_t=79a6Pj%2Fov9dhzgOmd4MC%2FuaI%2BtckdddCpnaH14PJp9ERMVwi8LnwKPeMNppcdVBCvW06&amp;rqlang=cn&amp;rsv_enter=0&amp;rsv_dl=tb</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p>浏览器请求url地址</p>
<ul>
<li>当前url对应的响应+js+css+图片 ----&gt; elements中的内容</li>
</ul>
</li>
<li>
<p>爬虫请求的url地址</p>
<ul>
<li>当前url对应的响应</li>
</ul>
</li>
<li>
<p>elements 的内容和爬虫获取到的url地址的响应不同，爬虫中需要以当前url地址对应的响应为准确提取数据</p>
</li>
<li>
<p>当前url地址对应的响应在哪儿？</p>
<ul>
<li>从network中找到当前的url地址，点击response</li>
<li>在页面上右键显示网页源码</li>
</ul>
</li>
</ul>
<h2 id="认识http-https"><a class="markdownIt-Anchor" href="#认识http-https"></a> 认识HTTP、HTTPS</h2>
<ul>
<li>
<p>HTTP：超文本传输协议</p>
<ul>
<li>以明文的形式传输</li>
</ul>
</li>
<li>
<p>HTTPS：HTTP + SSL(安全套接字层)</p>
<ul>
<li>
<p>传输之前数据先加密，之后解密获取内容</p>
</li>
<li>
<p>效率较低，但是安全</p>
</li>
</ul>
</li>
<li>
<p>Get 请求 和 Post 请求的区别</p>
<ul>
<li>
<p>get请求没有请求体，post有，get请求把数据放到url地址中</p>
</li>
<li>
<p>post请求常用登录注册</p>
</li>
<li>
<p>post请求携带的数据量比get请求大，多，常用于传输大文本的时候</p>
</li>
</ul>
</li>
<li>
<p>HTTP协议之请求</p>
<ol>
<li>
<p>请求行</p>
</li>
<li>
<p>请求头（Headers）</p>
<ul>
<li>User-Agent：用户代理：对方服务器能够通过user-agent知道当前请求对方资源的是什么浏览器</li>
<li>Connnection：Keep-alive：告诉对方我支不支持长连接</li>
<li>Accept-Encoding：gzip：为了使传输更快，一般会对数据进行压缩</li>
<li>Accept：text/html；q=0.9,image/web;q=0.8：指定接收的数据类型，q应该概率。</li>
<li>Accept-language：zh-CN；zh：指定支持语言的优先级</li>
<li>Cookie：用来存储用户信息，每次请求都会被携带上发送给对方的浏览器。
<ul>
<li>要获取登录后才能访问的页面</li>
<li>对方的服务器会通过cookie来判断我们一个爬虫</li>
</ul>
</li>
</ul>
</li>
<li>
<p>请求体</p>
<ul>
<li>携带数据</li>
<li>get请求没有请求体</li>
<li>post请求有请求体</li>
</ul>
</li>
</ol>
</li>
<li>
<p>HTTP协议之响应</p>
<ul>
<li>响应头
<ul>
<li>大部分不用注意，只有一个属性<code>set cookie</code></li>
<li>Set-Cookie：对方服务器通过该字段设置cookie到本地</li>
<li>直接F12 <code>response</code>旁边就是<code>cookie</code>关注两个属性，<code>字典：Name-Value</code></li>
</ul>
</li>
<li>响应体</li>
</ul>
</li>
</ul>
<h1 id="requests-模块的学习"><a class="markdownIt-Anchor" href="#requests-模块的学习"></a> requests 模块的学习</h1>
<h2 id="使用前安装"><a class="markdownIt-Anchor" href="#使用前安装"></a> 使用前：安装</h2>
<ul>
<li>pip install requests</li>
</ul>
<h2 id="发送getpost请求获取响应"><a class="markdownIt-Anchor" href="#发送getpost请求获取响应"></a> 发送get,post请求，获取响应</h2>
<ul>
<li>
<p><code>response = requests.get(url)</code>#发送get请求，请求url地址对应的响应</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">"http://www.baidu.com"</span></span><br><span class="line">response = requests.get(url)</span><br><span class="line">print(response) <span class="comment"># 返回的是状态码</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p><code>response = requests.post(url,data={请求字典})</code>#需要多传入一个请求体</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url=<span class="string">"http://fanyi.baidu.com/basetrans"</span></span><br><span class="line">query_string=&#123;<span class="string">"query"</span>：<span class="string">"人生苦短，我用python"</span>，</span><br><span class="line">			<span class="string">"from"</span>：<span class="string">"zh"</span>，</span><br><span class="line">			<span class="string">"tol"</span>：<span class="string">"en"</span>&#125;</span><br><span class="line">response = requests.post(url，data=query_string)</span><br><span class="line"><span class="keyword">print</span>（response）</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="response的方法"><a class="markdownIt-Anchor" href="#response的方法"></a> response的方法</h2>
<ul>
<li><code>response.text</code>
<ul>
<li>该方式往往会出现乱码</li>
<li>所以在生成text之前需要先编码一下：<code>response.encoding=&quot;utf-8&quot;</code></li>
</ul>
</li>
<li><code>response.content</code>
<ul>
<li><code>print(response.content())</code>输出的是<code>b&quot;str&quot;</code>二进制文件</li>
<li>把相应的<strong>二进制字节流</strong>转换为str类型<code>response.content.decode()</code></li>
</ul>
</li>
<li>属性
<ol>
<li>response.request.url # 发送请求的url地址</li>
<li>response.url # response相应的url地址</li>
<li>response.requests.headers # 请求头</li>
<li>response.headers # 相应请求</li>
</ol>
</li>
</ul>
<h2 id="获取网页源码的正确打开方式"><a class="markdownIt-Anchor" href="#获取网页源码的正确打开方式"></a> 获取网页源码的正确打开方式</h2>
<blockquote>
<p>通过下面三种方式一定能够获取到网页的正确解码之后的字符串)</p>
</blockquote>
<ol>
<li><code>response.content.decode</code>（默认按照utf-8解码）</li>
<li><code>response.content.decode(&quot;gbk&quot;)</code></li>
<li><code>respnse.text</code>浏览器以猜的方式解码，比较准确</li>
</ol>
<h2 id="发送带header的请求"><a class="markdownIt-Anchor" href="#发送带header的请求"></a> 发送带header的请求</h2>
<p>即，request headers 请求头中的键值对：为了模拟浏览器，获取和浏览器一模一样的内容。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headers=&#123;</span><br><span class="line"><span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0(iPhone; CPU iPhone 0S 10_3 like Mac0S X)ApplewebKit/602.1.50(KHTML, like Gecko)Cri0S/56.0.2924.75 Mobile/14E5239e Safari/602.1"</span>,</span><br><span class="line"><span class="string">"Referer"</span>:<span class="string">"http://fanyi. baidu. com/? aldtype=160471"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将头信息传入requests模块中:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">response = requests.post(url,data=query,headers = headers)</span><br></pre></td></tr></table></figure>
<h2 id="使用超时参数"><a class="markdownIt-Anchor" href="#使用超时参数"></a> 使用超时参数</h2>
<ul>
<li>requests.get(url,headers,timeout=3) #3 秒内必须返回响应，否则会报错。</li>
</ul>
<h2 id="retrying-模块的学习"><a class="markdownIt-Anchor" href="#retrying-模块的学习"></a> retrying 模块的学习</h2>
<ul>
<li>pip install retrying</li>
<li>具体的使用</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> retrying <span class="keyword">import</span> retry </span><br><span class="line"></span><br><span class="line"><span class="meta">@retry(stop_max_attempt_number =3 ) #让下面的模块反复执行三次</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_parse_url</span><span class="params">(url)</span>:</span></span><br><span class="line">    response = requests.get(url,headers=headers,timeout=<span class="number">5</span>)</span><br><span class="line">    <span class="keyword">return</span> response.content.decode()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_url</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html_str = _parse_url(url)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        html_str = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> html_str</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ = <span class="string">"__main__"</span></span><br><span class="line">	url = <span class="string">"https://www.baidu,com"</span></span><br><span class="line">  print(parse_url(url))</span><br></pre></td></tr></table></figure>
<h2 id="处理cookie相关的请求"><a class="markdownIt-Anchor" href="#处理cookie相关的请求"></a> 处理Cookie相关的请求</h2>
<ul>
<li>
<p>人人网{“<a href="mailto:email%22:%22mr_mao_hacker@163.com" target="_blank" rel="noopener">email&quot;:&quot;mr_mao_hacker@163.com</a>”,“password”:“alarmchime”}</p>
</li>
<li>
<p>直接携带cookie请求url地址</p>
<ol>
<li>
<p>cookie 直接放在headers中，传入request</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headers = &#123;<span class="string">"user-agent"</span>: <span class="string">""</span>,<span class="string">"Cookie"</span>:<span class="string">""</span>&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>requests 语法内单独设置了cookies 传入位置【字典格式】</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 正常cookie</span></span><br><span class="line">cookie = “”</span><br><span class="line">cookie_dict = &#123;i.split(<span class="string">"="</span>)[<span class="number">0</span>]:i.split(<span class="string">"="</span>)[<span class="number">1</span>]<span class="keyword">for</span> i <span class="keyword">in</span> cookie.split(<span class="string">";"</span>)&#125;</span><br><span class="line"></span><br><span class="line">response = requests.get(url,headers = headers,cookies = cookie_dict)</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li>
<p>先发送post请求，获取cookie，带上cookie请求登录后的页面</p>
<ol>
<li>session = requests.session() # session具有的方法和requests一样</li>
<li>session.post(url,data,headers) #服务器设置在本地的cookie会被存在session</li>
<li>session.get(url)#会带上之前保存在session中的cookie，能够成功</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">session = requests.session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用session 发送post请求，获取对方保存在本地的cookie</span></span><br><span class="line">post_url = <span class="string">"https://www.wuxiaworld.com/account/login"</span></span><br><span class="line">headers = &#123;<span class="string">"user-agent"</span>:<span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36"</span>&#125;</span><br><span class="line">post_data = &#123;<span class="string">"Email"</span>: <span class="string">"2409277719@qq.com"</span>,</span><br><span class="line">             <span class="string">"Password"</span>: <span class="string">"Wangjiahao526"</span>,</span><br><span class="line">             <span class="string">"__RequestVerificationToken"</span>:<span class="string">" CfDJ8EwF1hLhM7pChLwkXvZCy55dmm-LnHaweNXreDzH7f9Q3nKbP1PtMCURW_HUeR3CjYSk4tRFYDmihxf89hMNpB9nQbGZgnGve_MMrM6iLfE348bxJv1iFcx_KL4se8y-GnBq-y_KiP6-42Ai2UQ_8U0"</span>,</span><br><span class="line">             <span class="string">"RememberMe"</span>:<span class="string">"false"</span>&#125;</span><br><span class="line"></span><br><span class="line">response = session.post(post_url,headers=headers,data=post_data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以上应该能登录成功，成功后登录之前登录不上的个人页面</span></span><br><span class="line">url = <span class="string">"https://www.wuxiaworld.com/profile/bookmarks"</span></span><br><span class="line">response = session.get(url,headers = headers)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"wuxiaworld3.html"</span>,<span class="string">"w"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(response.content.decode())</span><br></pre></td></tr></table></figure>
<blockquote>
<p>两种方法获取以上的信息</p>
<ol>
<li>
<p>浏览器的element查找，如需要传入关键字&quot;Password&quot;密码</p>
<p>&lt;input type=“password” class=“form-control valid” placeholder=“Password” data-val=“true” data-val-required=“The Password field is required.” id=“Password” name=“Password” aria-describedby=“Password-error” aria-invalid=“false”&gt;</p>
</li>
<li>
<p>抓包，记住勾选 [ ]preserved log</p>
<ul>
<li>清空后，点击登录按钮，在Network中查找</li>
</ul>
</li>
</ol>
</blockquote>
</li>
</ul>
<h1 id="️数据提取方法"><a class="markdownIt-Anchor" href="#️数据提取方法"></a> ⭐️数据提取方法</h1>
<h2 id="json格式介绍"><a class="markdownIt-Anchor" href="#json格式介绍"></a> json格式介绍</h2>
<ul>
<li>
<p>数据交换格式，看起来像python类型（列表，字典）的字符串</p>
<p><img alt data-src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/image-20191201201110586.png" class="lozad"></p>
</li>
<li>
<p>使用<code>json</code>之前需要导入json库</p>
</li>
<li>
<p>哪儿会返回json的数据</p>
<ul>
<li>浏览器切换到手机版</li>
<li>抓包<code>app</code></li>
</ul>
</li>
</ul>
<h3 id="json语法介绍"><a class="markdownIt-Anchor" href="#json语法介绍"></a> Json语法介绍</h3>
<h4 id="jsonloads"><a class="markdownIt-Anchor" href="#jsonloads"></a> json.loads</h4>
<ul>
<li>把json字符串转换为python类型</li>
<li><code>json.loads(json字符串)</code></li>
<li>完整代码【百度翻译】</li>
</ul>
<h4 id="jsondumps"><a class="markdownIt-Anchor" href="#jsondumps"></a> json.dumps</h4>
<ul>
<li>把python类型转换为json字符串</li>
<li><code>json.dumps({&quot;a&quot;:&quot;a&quot;,&quot;b&quot;:2})</code></li>
<li><code>json.dumps(ret1,ensure_ascii=False,indent=2))</code>
<ul>
<li>ensure_ascii：让中文显示成中文</li>
<li>indent：能够让下一行在上一行的基础上空格</li>
<li>推荐使用这个函数，可以控制写入文件的一些参数</li>
</ul>
</li>
</ul>
<h3 id="案例豆瓣获取美剧分类爬虫案例"><a class="markdownIt-Anchor" href="#案例豆瓣获取美剧分类爬虫案例"></a> 案例：豆瓣获取美剧分类爬虫案例</h3>
<blockquote>
<p>手机版可以返回Json格式</p>
</blockquote>
<ul>
<li>
<p>如何找内容，同时在Resonse和Preview中查找<code>黑镜</code></p>
</li>
<li>
<p>遇到问题：缺少refer信息，导致的url地址无法访问。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">""</span></span><br><span class="line">headers = &#123;</span><br><span class="line">	<span class="string">"User-Agent"</span>:<span class="string">""</span></span><br><span class="line">	<span class="string">"Referer"</span>:<span class="string">""</span>&#125;</span><br><span class="line">response = requests.get(url,headers= headers)</span><br><span class="line">print(response.content.decode())</span><br><span class="line"></span><br><span class="line">json_str = response.content.decode()</span><br><span class="line"></span><br><span class="line">ret1 = json.loads(json_str)<span class="comment">#转换为python类型</span></span><br><span class="line">print(ret1)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"douban.txt"</span>,<span class="string">"w"</span>,encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(json.dumps(ret1,ensure_ascii=<span class="literal">False</span>,indent=<span class="number">2</span>))<span class="comment"># indent 能达到换行空两格的效果，因为直接write就是一行内容，ensure_ascii能够直接不以ASCII格式保存字符</span></span><br></pre></td></tr></table></figure>
<ul>
<li>如果url中有callback，没有用可以直接删掉，否则响应不是一个Json格式会报错</li>
</ul>
</li>
<li>
<p>暂补内容</p>
<ul>
<li>实例化</li>
<li>def run</li>
<li>查询具体url的变化趋势：每次加18以及有个Total值</li>
<li>定义 class 可以整理思路</li>
</ul>
</li>
</ul>
<h2 id="xpath-和-lxml"><a class="markdownIt-Anchor" href="#xpath-和-lxml"></a> Xpath 和 lxml</h2>
<ul>
<li>
<p>xpath</p>
<ul>
<li>一门从html中提取数据的语言</li>
</ul>
</li>
</ul>
<h3 id="xpath语法"><a class="markdownIt-Anchor" href="#xpath语法"></a> xpath语法</h3>
<ul>
<li>xpath helper：帮助我们从<code>elements</code>中定位数据【爬虫爬不到这个内容】</li>
<li>判断是否定位到相应的属性：多`xh-highlight``</li>
</ul>
<ol>
<li>
<p>选择节点（标签）</p>
<p><code>html/head/meta</code>：能够选中html下的head下的所有的meta标签</p>
</li>
<li>
<p><code>//</code>：能够从任意节点开始选择</p>
<p><code>//li</code>：当前页面上所有的<code>li</code>标签</p>
<p><code>/html/head//link</code>：head下的所有的<code>link</code>标签</p>
</li>
<li>
<p><code>@符号的用法</code></p>
</li>
</ol>
<ul>
<li>选择具体某个元素：<code>//div[@class='feed-infinite-wrapper']/ul/li</code>
<ul>
<li>选择class='feed-infinite-wrapper’的<code>div</code>下的<code>ul</code>下的<code>li</code></li>
</ul>
</li>
<li>直接选择某个属性的值：<code>a/@href</code>选择a的href的值</li>
</ul>
<ol start="4">
<li>
<p>获取文本</p>
<ul>
<li><code>/a/text()</code>：a下的标签</li>
<li><code>a//text()</code>：a下的所有文本，可以选到span中的所有内容</li>
</ul>
</li>
<li>
<p>当前</p>
<ul>
<li><code>./a</code>当前节点下的a标签</li>
</ul>
</li>
</ol>
<ul>
<li>
<p>lxml</p>
<ul>
<li>
<p>安装：<code>pip install lxml</code></p>
</li>
<li>
<p>使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">element = etree.HTML(“html字符串”)</span><br><span class="line">element.xpath(<span class="string">""</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="爬虫实例获取某瓣的标题url图片地址评论数评分等信息"><a class="markdownIt-Anchor" href="#爬虫实例获取某瓣的标题url图片地址评论数评分等信息"></a> 爬虫实例：获取某瓣的标题，url，图片地址，评论数，评分等信息</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://movie/douban.com/chart"</span></span><br><span class="line">headers = &#123;<span class="string">"User-Agent"</span>:<span class="string">""</span>&#125;</span><br><span class="line"></span><br><span class="line">response = requests.get(url,headers=headers)</span><br><span class="line">html_str = response.content.decode()</span><br><span class="line"></span><br><span class="line">print(html_str)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用etree处理数据</span></span><br><span class="line">html = etree.HTML(html_str)</span><br><span class="line">print(html)<span class="comment"># 这里得到的是一个element对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里写xpath必须按照网页源内容写，而不能按照element内容写（之前的做法是错误的）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#1.获取所有的电影的url地址</span></span><br><span class="line">url_list = html.xpath(<span class="string">""</span>)</span><br><span class="line">print(url_list)</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.获取所有图片的地址</span></span><br><span class="line">img_list = html.xpath(<span class="string">""</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#3.需要把每部电影组成一个字典，字典中是电影的各种数据，比如标题，url，图片地址，评论数，评分</span></span><br><span class="line"><span class="comment"># 思路：</span></span><br><span class="line"><span class="comment">#1.分组</span></span><br><span class="line"><span class="comment">#2.每一组提取数据</span></span><br><span class="line"></span><br><span class="line">ret1 = html.xpath(<span class="string">""</span>)<span class="comment">#取出的实际上是element，我们依然可以使用xpath</span></span><br><span class="line">print(ret1)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> table <span class="keyword">in</span> ret1:</span><br><span class="line">    item = &#123;&#125;</span><br><span class="line">    item[<span class="string">"title"</span>] = table.xpath(<span class="string">""</span>)</span><br><span class="line">    item[<span class="string">"href"</span>] = table.xpath(<span class="string">""</span>)</span><br><span class="line">    item[<span class="string">"img"</span>] = table.xpath(<span class="string">""</span>)</span><br><span class="line">    item[<span class="string">"comment_num"</span>] = table.xpath(<span class="string">"./"</span>)</span><br><span class="line">    item[<span class="string">"rating_num"</span>] = table.xpath(<span class="string">"./"</span>)</span><br><span class="line">    print(item)</span><br></pre></td></tr></table></figure>
<h3 id="基础知识点的学习"><a class="markdownIt-Anchor" href="#基础知识点的学习"></a> 基础知识点的学习</h3>
<ul>
<li>
<p>format:字符串格式化的一种方式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">"传智&#123;&#125;播客"</span>.format(<span class="number">1</span>)</span><br><span class="line"><span class="string">"传智&#123;&#125;播客"</span>.format([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="string">"传智&#123;&#125;播客"</span>.format(&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;)</span><br><span class="line"><span class="string">"传智&#123;&#125;播客&#123;&#125;"</span>.format(&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;,[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="string">"传智&#123;&#125;播客&#123;&#125;"</span>.format(&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>列表推导式</p>
<ul>
<li>
<p>帮助我们快速的生成包含一堆数据的列表</p>
<p><code>[i+10 for i in range(10)]</code>–&gt; [10,11,12,…,19]</p>
<p><code>[&quot;10月{}日&quot;.format(i) for i in range(1,10)]</code>–&gt;[“10月1日”,“10月2日”,“10月3日”]</p>
</li>
</ul>
</li>
<li>
<p>字典推导式</p>
<ul>
<li>
<p>帮助我们快速的生成包含一堆数据的字典</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;i+<span class="number">10</span>:i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)&#125;</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">"a&#123;&#125;"</span>.format(i):<span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>)&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p>三元运算符</p>
<ul>
<li>if 后面的条件成立，就把if前面的结果赋值给a，否则把else喂给a</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="number">10</span> <span class="keyword">if</span> <span class="number">4</span>&gt;<span class="number">3</span> <span class="keyword">else</span> <span class="number">20</span> <span class="comment"># a=10</span></span><br><span class="line">a = <span class="number">10</span> <span class="keyword">if</span> <span class="number">4</span>&lt;<span class="number">3</span> <span class="keyword">else</span> <span class="number">20</span> <span class="comment"># a=20</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="最终案例"><a class="markdownIt-Anchor" href="#最终案例"></a> 最终案例</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QiubaiSpider</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__int__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.url_temp = <span class="string">"https://www.qiushibaike.com/8hr/page/&#123;&#125;/"</span></span><br><span class="line">        self.headers = &#123;<span class="string">"User-Agent"</span>:<span class="string">""</span>&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_url_list</span><span class="params">(self)</span>:</span><span class="comment">#根据url地址的规律，构造url list</span></span><br><span class="line">        url = [self.url_temp.format&#123;i&#125; <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">14</span>)]</span><br><span class="line">        <span class="keyword">return</span> url_list</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_url</span><span class="params">(self,url)</span>:</span></span><br><span class="line">        print(<span class="string">"now parseing :"</span>,url)</span><br><span class="line">        response = requests.get(url,headers=headers)</span><br><span class="line">        <span class="keyword">return</span> response.content.decode()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_content_list</span><span class="params">(self,html_str)</span>:</span><span class="comment">#3.提取数据</span></span><br><span class="line">        html = etree.HTML(html_str)</span><br><span class="line">        <span class="comment">#1.分组</span></span><br><span class="line">        div_list = html.xpath(<span class="string">""</span>)</span><br><span class="line">        <span class="keyword">for</span> div <span class="keyword">in</span> div_list:</span><br><span class="line">            item = &#123;&#125;</span><br><span class="line">            item[<span class="string">"author_name"</span>] = div.xpath(<span class="string">"./"</span>) <span class="keyword">if</span> len(div.xpath(<span class="string">"./"</span>))&gt;<span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">            item[<span class="string">'content'</span>] = div.xpath(<span class="string">"./"</span>)</span><br><span class="line">            <span class="comment"># 技巧：可以在element里面直接复制 xpath</span></span><br><span class="line">            item[<span class="string">"img"</span>] = <span class="string">"https:"</span>+item[<span class="string">"img"</span>][<span class="number">0</span>] <span class="keyword">if</span> len(item[<span class="string">"img"</span>])&gt;<span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span> </span><br><span class="line">            content_list.append(item)</span><br><span class="line">     <span class="keyword">return</span> content_list</span><br><span class="line">    	</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save_content_list</span><span class="params">(self,content_list)</span>:</span><span class="comment">#保存</span></span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">"qiubai.txt"</span>,<span class="string">"a"</span>,encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> content <span class="keyword">in</span> content_list:</span><br><span class="line">                f.write(json.dumps(content,ensure_ascii=<span class="literal">False</span>))</span><br><span class="line">                f.write(<span class="string">"\n"</span>)</span><br><span class="line">        print(<span class="string">"保存成功"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span>实现主要逻辑</span><br><span class="line">        <span class="comment">#1.根据url地址的规律，构造url list(爬取豆瓣时,直接获取的方式得到地址)</span></span><br><span class="line">        url_list = self.get_url_list()</span><br><span class="line">        <span class="comment">#2.发送请求，获取相应</span></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> url_list:</span><br><span class="line">        	html_str = self.parse_url(url)</span><br><span class="line">        	<span class="comment">#3.提取数据</span></span><br><span class="line">        	content_list = self.get_content_list(html_str)</span><br><span class="line">        	<span class="comment">#4.保存(调用下方法即可)</span></span><br><span class="line">        	self.save_content_list(content_list)</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    qiubai = QiubaiSpider()</span><br><span class="line">    qiubai.run</span><br><span class="line"><span class="comment">#对于列表不能直接strip()，可以用列表循环去 strip()</span></span><br></pre></td></tr></table></figure>
<h3 id="写爬虫的讨论"><a class="markdownIt-Anchor" href="#写爬虫的讨论"></a> 写爬虫的讨论</h3>
<ol>
<li>url
<ul>
<li>知道url地址的规律和总得页码数：构造url地址的列表【没有办法确定】</li>
<li>start_url：构造法</li>
</ul>
</li>
<li>发送请求，获取响应
<ul>
<li>request</li>
</ul>
</li>
<li>提取数据
<ul>
<li>返回json字符串：json模块</li>
<li>返回的是html字符串：lxml模块配和xpath提取数据</li>
</ul>
</li>
<li>保存</li>
</ol>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">Jacky</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://wangjs-jacky.github.io/2019/12/09/%E4%BC%A0%E4%BC%A0%E6%99%BA%E6%92%AD%E5%AE%A2_%E5%85%AD%E8%8A%82%E7%88%AC%E8%99%AB%E8%AF%BE/">https://wangjs-jacky.github.io/2019/12/09/%E4%BC%A0%E4%BC%A0%E6%99%BA%E6%92%AD%E5%AE%A2_%E5%85%AD%E8%8A%82%E7%88%AC%E8%99%AB%E8%AF%BE/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://wangjs-jacky.github.io">Jacky's blogs</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/爬虫.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull-left"><a href="/2019/12/09/%E8%AE%BA%E6%96%87%E6%A8%A1%E6%9D%BF%E8%AE%BE%E7%BD%AE/"><img class="prev_cover lozad" data-src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/20191220194135.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>论文模板设置</span></div></a></div><div class="next-post pull-right"><a href="/2019/12/04/%E5%AE%9E%E7%94%A8%E7%BD%91%E7%AB%99%E6%94%B6%E9%9B%86/"><img class="next_cover lozad" data-src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/20200122221103.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>实用网站收集</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/10/30/超简易爬虫入门/" title="超简易爬虫入门"><img class="relatedPosts_cover lozad"data-src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/爬虫.png"><div class="relatedPosts_title">超简易爬虫入门</div></a></div></div><div class="clear_both"></div></div></div></div><footer><div id="footer"><div class="copyright">&copy;2019 - 2020 By Jacky</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="http://wangjs-jacky.github.io">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换">繁</a><i class="nightshift fa fa-moon-o" id="nightshift" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function () {
  $('span.katex-display').wrap('<div class="katex-wrap"></div>')
})</script><script async src="/js/search/local-search.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="/js/nightshift.js"></script><script color="0,0,255" opacity="0.7" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN/js/canvas-nest.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script>const observer = lozad(); // lazy loads elements with default selector as '.lozad'
observer.observe();
</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>