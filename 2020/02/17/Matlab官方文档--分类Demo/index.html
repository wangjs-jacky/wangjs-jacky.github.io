<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Matlab官方文档--分类Demo | Jacky's blogs</title><meta name="description" content="Matlab官方文档--分类Demo"><meta name="keywords" content="Matlab编程"><meta name="author" content="Jacky"><meta name="copyright" content="Jacky"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="https://wangjs-jacky.github.io/2020/02/17/Matlab%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3--%E5%88%86%E7%B1%BBDemo/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Matlab官方文档--分类Demo"><meta name="twitter:description" content="Matlab官方文档--分类Demo"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/20200217134252.png"><meta property="og:type" content="article"><meta property="og:title" content="Matlab官方文档--分类Demo"><meta property="og:url" content="https://wangjs-jacky.github.io/2020/02/17/Matlab%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3--%E5%88%86%E7%B1%BBDemo/"><meta property="og:site_name" content="Jacky's blogs"><meta property="og:description" content="Matlab官方文档--分类Demo"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/20200217134252.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="next" title="黑马程序员--聚类算法" href="https://wangjs-jacky.github.io/2020/02/17/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98--%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: '添加书签',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  copyright: undefined,
  copy_copyright_js: false
  
}</script></head><body><canvas class="fireworks"></canvas><div id="header"> <div id="page-header"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Jacky's blogs</a></span><i class="fa fa-bars fa-fw toggle-menu pull-right close" aria-hidden="true"></i><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/categories/SklearnAPI"><i class="fa-fw fa fa-music"></i><span> SklearnAPI</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 列表</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lozad avatar_img" src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/小李.jpg" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">48</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">18</div></a></div></div><div class="mobile_data_item is_center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">54</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/categories/SklearnAPI"><i class="fa-fw fa fa-music"></i><span> SklearnAPI</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 列表</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#matlab官方文档分类demo"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text"> Matlab官方文档–分类Demo</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#fishers-iris-data"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text"> Fisher’s Iris Data</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#linear-and-quadratic-discriminant-analysis"><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text"> Linear and Quadratic Discriminant Analysis</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#naive-bayes-classifiers"><span class="toc_mobile_items-number">1.3.</span> <span class="toc_mobile_items-text"> Naive Bayes Classifiers</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#decision-tree"><span class="toc_mobile_items-number">1.4.</span> <span class="toc_mobile_items-text"> Decision Tree</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#som"><span class="toc_mobile_items-number">1.5.</span> <span class="toc_mobile_items-text"> SOM</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1导入数据"><span class="toc_mobile_items-number">1.5.1.</span> <span class="toc_mobile_items-text"> 1.导入数据</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2创建neural-network"><span class="toc_mobile_items-number">1.5.2.</span> <span class="toc_mobile_items-text"> 2.创建Neural Network</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#21-神经网络中的细节设置"><span class="toc_mobile_items-number">1.5.2.1.</span> <span class="toc_mobile_items-text"> 2.1 神经网络中的细节设置</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3预测聚类结果"><span class="toc_mobile_items-number">1.5.3.</span> <span class="toc_mobile_items-text"> 3.预测聚类结果</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#4可视化结果"><span class="toc_mobile_items-number">1.5.4.</span> <span class="toc_mobile_items-text"> 4.可视化结果</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#代码总结"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text"> 代码总结：</span></a></li></ol></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#matlab官方文档分类demo"><span class="toc-number">1.</span> <span class="toc-text"> Matlab官方文档–分类Demo</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#fishers-iris-data"><span class="toc-number">1.1.</span> <span class="toc-text"> Fisher’s Iris Data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#linear-and-quadratic-discriminant-analysis"><span class="toc-number">1.2.</span> <span class="toc-text"> Linear and Quadratic Discriminant Analysis</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#naive-bayes-classifiers"><span class="toc-number">1.3.</span> <span class="toc-text"> Naive Bayes Classifiers</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#decision-tree"><span class="toc-number">1.4.</span> <span class="toc-text"> Decision Tree</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#som"><span class="toc-number">1.5.</span> <span class="toc-text"> SOM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1导入数据"><span class="toc-number">1.5.1.</span> <span class="toc-text"> 1.导入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2创建neural-network"><span class="toc-number">1.5.2.</span> <span class="toc-text"> 2.创建Neural Network</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#21-神经网络中的细节设置"><span class="toc-number">1.5.2.1.</span> <span class="toc-text"> 2.1 神经网络中的细节设置</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3预测聚类结果"><span class="toc-number">1.5.3.</span> <span class="toc-text"> 3.预测聚类结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4可视化结果"><span class="toc-number">1.5.4.</span> <span class="toc-text"> 4.可视化结果</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#代码总结"><span class="toc-number">2.</span> <span class="toc-text"> 代码总结：</span></a></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/20200217134252.png)"><div id="post-info"><div id="post-title"><div class="posttitle">Matlab官方文档--分类Demo</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-02-17<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-02-17</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Matlab%E7%BC%96%E7%A8%8B/">Matlab编程</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Matlab%E7%BC%96%E7%A8%8B/%E5%88%86%E7%B1%BBDemo/">分类Demo</a></span><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">2k</span><span class="post-meta__separator">|</span><span>阅读时长: 7 分钟</span><span class="post-meta__separator">|</span><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="matlab官方文档分类demo"><a class="markdownIt-Anchor" href="#matlab官方文档分类demo"></a> Matlab官方文档–分类Demo</h1>
<h2 id="fishers-iris-data"><a class="markdownIt-Anchor" href="#fishers-iris-data"></a> Fisher’s Iris Data</h2>
<p>Fisher的iris data 的特征包含如下：</p>
<ul>
<li>Sepal length in cm</li>
<li>Sepal width in cm</li>
<li>Petal length in cm</li>
<li>Petal width in cm</li>
</ul>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">load fisheriris</span><br><span class="line"># meas (150,4)</span><br><span class="line"># species (150,1)cell 标签数据，只有三个数据</span><br><span class="line"># 通过这段代码学习gscatter的写法，先输入x和有，再输入标签值，后面是形状和颜色</span><br><span class="line">gscatter(meas(:,<span class="number">1</span>), meas(:,<span class="number">2</span>), species,<span class="string">'rgb'</span>,<span class="string">'osd'</span>);</span><br><span class="line">xlabel(<span class="string">'Sepal length'</span>);</span><br><span class="line">ylabel(<span class="string">'Sepal width'</span>);</span><br><span class="line">N = <span class="built_in">size</span>(meas,<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<h2 id="linear-and-quadratic-discriminant-analysis"><a class="markdownIt-Anchor" href="#linear-and-quadratic-discriminant-analysis"></a> Linear and Quadratic Discriminant Analysis</h2>
<p>fitcdiscr可以调用不同的discriminant analysis方法。默认使用LDA取分类数据。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">lda = fitcdiscr(meas(:,1:2),species); # 默认LDA训练</span><br><span class="line"># resub 的全称 resubstitution 重构</span><br><span class="line">ldaClass = resubPredict(lda); # 预测</span><br></pre></td></tr></table></figure>
<p>计算重构错误，也即错分误差（再训练样本中错分的比例）</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">ldaResubErr = resubLoss(lda)</span><br><span class="line"># ldaResubErr = 0.2000</span><br></pre></td></tr></table></figure>
<p>也可以计算<strong>混淆矩阵</strong>，i代表原先的类别，j代表预测的类别。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">[ldaResubCM,grpOrder] = confusionmat(species,ldaClass)</span><br><span class="line"># ldaResubCM =</span><br><span class="line">#    49     1     0</span><br><span class="line">#     0    36    14</span><br><span class="line">#     0    15    35</span><br><span class="line">#  grpOrder =</span><br><span class="line">#  3x1 cell array</span><br><span class="line">#   &#123;'setosa'    &#125;</span><br><span class="line">#   &#123;'versicolor'&#125;</span><br><span class="line">#   &#123;'virginica' &#125;</span><br></pre></td></tr></table></figure>
<p>绘制分类错误的点，<code>strcmp</code>字符比较函数</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">bad = ~strcmp(ldaClass,species);</span><br><span class="line"><span class="built_in">hold</span> on;</span><br><span class="line"><span class="built_in">plot</span>(meas(bad,<span class="number">1</span>), meas(bad,<span class="number">2</span>), <span class="string">'kx'</span>);</span><br><span class="line"><span class="built_in">hold</span> off;</span><br></pre></td></tr></table></figure>
<p>绘制判别边界，待预测空间内打点 --》 预测</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">[x,y] = <span class="built_in">meshgrid</span>(<span class="number">4</span>:<span class="number">.1</span>:<span class="number">8</span>,<span class="number">2</span>:<span class="number">.1</span>:<span class="number">4.5</span>);</span><br><span class="line">x = x(:);</span><br><span class="line">y = y(:);</span><br><span class="line"><span class="built_in">j</span> = classify([x y],meas(:,<span class="number">1</span>:<span class="number">2</span>),species);</span><br><span class="line">gscatter(x,y,<span class="built_in">j</span>,<span class="string">'grb'</span>,<span class="string">'sod'</span>)</span><br></pre></td></tr></table></figure>
<p>对于某些问题来说，LDA不够用了，需要用到quadratic discriminant analysis （QDA）</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">qda = fitcdiscr(meas(:,<span class="number">1</span>:<span class="number">2</span>),species,<span class="string">'DiscrimType'</span>,<span class="string">'quadratic'</span>);</span><br><span class="line">qdaResubErr = resubLoss(qda)</span><br><span class="line"># qdaResubErr = 0.2000</span><br></pre></td></tr></table></figure>
<p>你可以计算resubstitution error（重构误差），通常会低估了test error。我们会用交叉验证，比如10 - 折。随机划分数据集。1折验证，9折计算。为了保证每次随机性的结果，所以需要设置随机种子。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">rng(<span class="number">0</span>,<span class="string">'twister'</span>);</span><br></pre></td></tr></table></figure>
<p>首先使用<code>cvpartition</code>取划分出10个不同的子数据</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">cp = cvpartition(species,<span class="string">'KFold'</span>,<span class="number">10</span>)</span><br><span class="line">#cp = </span><br><span class="line">#K-fold cross validation partition</span><br><span class="line">#   NumObservations: 150</span><br><span class="line">#       NumTestSets: 10</span><br><span class="line">#         TrainSize: 135  135  135  135  135  135  135  135  135  135</span><br><span class="line">#          TestSize: 15  15  15  15  15  15  15  15  15  15</span><br></pre></td></tr></table></figure>
<p><code>crossval</code> 和 <code>kfoldLoss</code> 能计算LDA 和QDA的错分误差</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">cvlda = crossval(lda,<span class="string">'CVPartition'</span>,cp);</span><br><span class="line">ldaCVErr = kfoldLoss(cvlda)</span><br><span class="line">#ldaCVErr =   0.2000</span><br><span class="line"></span><br><span class="line">cvqda = crossval(qda,<span class="string">'CVPartition'</span>,cp);</span><br><span class="line">qdaCVErr = kfoldLoss(cvqda)</span><br></pre></td></tr></table></figure>
<h2 id="naive-bayes-classifiers"><a class="markdownIt-Anchor" href="#naive-bayes-classifiers"></a> Naive Bayes Classifiers</h2>
<p>上面的<code>fitcdiscr</code>只能提供两种模式 ‘DiagLinear’ and ‘DiagQuadratic’。它们相似于 ‘linear’ and ‘quadratic’，但是是对角协方差估计，可以看作是Naive Bayes Classifier的特殊形式。因为NBC 可以根据标签有条件的设置变量间的独立。尽管变量间的class-conditional independence通常是不对的，但是实际例子效果不错。</p>
<p><code>fitcnb</code>可以被使用过去创建一个更加通用的naive Bayes classifier的类型。</p>
<p>通常默认每个类是服从高斯分布，你可以计算resubstitution error 和  cross-validation error。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">nbGau = fitcnb(meas(:,<span class="number">1</span>:<span class="number">2</span>), species);</span><br><span class="line">nbGauResubErr = resubLoss(nbGau)</span><br><span class="line">nbGauCV = crossval(nbGau, <span class="string">'CVPartition'</span>,cp);</span><br><span class="line">nbGauCVErr = kfoldLoss(nbGauCV)</span><br><span class="line"></span><br><span class="line">labels = predict(nbGau, [x y]);</span><br><span class="line">gscatter(x,y,labels,<span class="string">'grb'</span>,<span class="string">'sod'</span>)</span><br></pre></td></tr></table></figure>
<p>迄今为止你已经假设了每个类别中的变量服从多元高斯分布。通常是合理的假设，但是有的时候你不是很希望取做出这个假设，或者你已经很明显的可以看出这个是不合理的。现在尝试给每个类别中的变量建模通过使用一个kernel density estimation，这是一个更加灵活的非参数化技术。这里我们设置 kernel 给 box 。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">nbKD = fitcnb(meas(:,<span class="number">1</span>:<span class="number">2</span>), species, <span class="string">'DistributionNames'</span>,<span class="string">'kernel'</span>,<span class="string">'Kernel'</span>,<span class="string">'box'</span>);</span><br><span class="line">nbKDResubErr = resubLoss(nbKD)</span><br><span class="line">nbKDCV = crossval(nbKD, <span class="string">'CVPartition'</span>,cp);</span><br><span class="line">nbKDCVErr = kfoldLoss(nbKDCV)</span><br><span class="line"></span><br><span class="line">labels = predict(nbKD, [x y]);</span><br><span class="line">gscatter(x,y,labels,<span class="string">'rgb'</span>,<span class="string">'osd'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="decision-tree"><a class="markdownIt-Anchor" href="#decision-tree"></a> Decision Tree</h2>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">t = fitctree(meas(:,<span class="number">1</span>:<span class="number">2</span>), species,<span class="string">'PredictorNames'</span>,&#123;<span class="string">'SL'</span> <span class="string">'SW'</span> &#125;);</span><br></pre></td></tr></table></figure>
<p>另一种方式取可实话决策树：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">view(t,<span class="string">'Mode'</span>,<span class="string">'graph'</span>);</span><br></pre></td></tr></table></figure>
<p>查看误差：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">dtResubErr = resubLoss(t)</span><br><span class="line">cvt = crossval(t,<span class="string">'CVPartition'</span>,cp);</span><br><span class="line">dtCVErr = kfoldLoss(cvt)</span><br></pre></td></tr></table></figure>
<p>可以通过上面的结果可以发现 重构误差要远远小于cross error，原因可以通过绘制两个误差曲线的变化曲线解释：</p>
<p>若需要捕获决策树每层的误差，需要加上’Subtrees’,‘all’</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">resubcost = resubLoss(t,<span class="string">'Subtrees'</span>,<span class="string">'all'</span>);</span><br><span class="line">[cost,secost,ntermnodes,bestlevel] = cvloss(t,<span class="string">'Subtrees'</span>,<span class="string">'all'</span>);</span><br><span class="line"># 这里可以自动计算出最佳的层数</span><br><span class="line"># cost 里面放着 每层树 所对应的误差</span><br><span class="line"># ntermnodes 里面放着 每层树 所对应的结点</span><br><span class="line"><span class="built_in">plot</span>(ntermnodes,cost,<span class="string">'b-'</span>, ntermnodes,resubcost,<span class="string">'r--'</span>)</span><br><span class="line"><span class="built_in">figure</span>(gcf);</span><br><span class="line">xlabel(<span class="string">'Number of terminal nodes'</span>);</span><br><span class="line">ylabel(<span class="string">'Cost (misclassification error)'</span>)</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'Cross-validation'</span>,<span class="string">'Resubstitution'</span>)</span><br></pre></td></tr></table></figure>
<p>可以发现这里需要选择 cross - validation error 作为默认的误差方法，以此选择决策树的层数。可以通过以下的命令来直接删减树枝。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">pt = prune(t,<span class="string">'Level'</span>,bestlevel);</span><br><span class="line">view(pt,<span class="string">'Mode'</span>,<span class="string">'graph'</span>)</span><br></pre></td></tr></table></figure>
<p>查看误差：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">cost(bestlevel+<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h2 id="som"><a class="markdownIt-Anchor" href="#som"></a> SOM</h2>
<blockquote>
<p>这里简单的介绍SOM的Matlab的过程。</p>
</blockquote>
<h3 id="1导入数据"><a class="markdownIt-Anchor" href="#1导入数据"></a> 1.导入数据</h3>
<p>首先导入数据，因为每个人的数据是不同的，特别说明SOM属于无监督学习，所以只需要准备训练数据即可，无需标签数据。这里注意<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mtext> </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">input\ data</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">p</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span><span class="mspace"> </span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span></span></span></span>的维度是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>n</mi><mi mathvariant="normal">_</mi><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>e</mi><mi>s</mi><mo separator="true">,</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(n\_features, number)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">n</span><span class="mord mathdefault">u</span><span class="mord mathdefault">m</span><span class="mord mathdefault">b</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span></p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">load fisheriris</span><br><span class="line">x = iris_dataset;</span><br><span class="line"><span class="built_in">size</span>(x)</span><br></pre></td></tr></table></figure>
<h3 id="2创建neural-network"><a class="markdownIt-Anchor" href="#2创建neural-network"></a> 2.创建Neural Network</h3>
<p>通过<code>selforgmap</code>可以简单搭建一个SOM的专用网络模型。因为SOM属于一个特殊的神经网络模型，单输入单输出，且隐藏网络具有拓扑结构，无需输出结果。</p>
<p><code>selforgmap</code>函数的记忆方法是英文<code>Self - organization-map</code>的缩写。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">net = selforgmap([<span class="number">8</span>,<span class="number">8</span>])</span><br><span class="line">view(net)</span><br></pre></td></tr></table></figure>
<p>我一开始不小心把这个窗口关了，不知道怎么再打开，只需要<code>view</code>以下网络，这个窗口又打开了。</p>
<p><img alt data-src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/20200216114426.png" class="lozad"></p>
<p>上面发现input的输入是0，因为这个时候还没有输入数据进去。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">[net,tr] = train(net,x);</span><br><span class="line">nntraintool</span><br></pre></td></tr></table></figure>
<p>这里有个命令可以打开图形化界面，在这个界面提供一些<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mi>i</mi><mi>n</mi><mi>k</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">Links</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mord mathdefault">s</span></span></span></span>可以很方便地帮助我们快速的可视化聚类的结果。</p>
<img style="zoom:80%;" data-src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/20200216123734.png" class="lozad">
<h4 id="21-神经网络中的细节设置"><a class="markdownIt-Anchor" href="#21-神经网络中的细节设置"></a> 2.1 神经网络中的细节设置</h4>
<p>在命令窗下输入<code>net</code>可以查看训练过程中的一些属性参数：<code>net</code></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># functions:</span><br><span class="line">#     trainParam: .showWindow, .showCommandLine, .show, .epochs, .time</span><br></pre></td></tr></table></figure>
<p>参考输入：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">net.trainParam.showWindow = true # 布尔值，训练时是否打开GUI界面</span><br><span class="line">net.trainParam.showCommandLine = true # 布尔值，训练时是否打印输出</span><br><span class="line">net.trainParam.epochs = 500 # 迭代数</span><br><span class="line">net.trainParam.show = 2 # MiniBatch的步长</span><br><span class="line">[net,tr] = train(net,x);</span><br></pre></td></tr></table></figure>
<p>参考答应输出：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; [net,tr] = train(net,x);</span><br><span class="line">Calculation mode: MATLAB</span><br><span class="line"> </span><br><span class="line">Training Self-Organizing Map with TRAINBU.</span><br><span class="line">Epoch 0/500, Time 0.086</span><br><span class="line">Epoch 2/500, Time 0.149</span><br><span class="line">Epoch 4/500, Time 0.158</span><br><span class="line">Epoch 6/500, Time 0.169</span><br></pre></td></tr></table></figure>
<h3 id="3预测聚类结果"><a class="markdownIt-Anchor" href="#3预测聚类结果"></a> 3.预测聚类结果</h3>
<p>做到上面这一步，整个聚类过程其实就已经完成了，因为SOM属于无监督聚类，所以只需要训练数据即可，若是需要用训练好的网络对类别进行预测，直接调用<code>net</code>方法。</p>
<p>我一般习惯会先习惯查看一下Weight Positions值，因为权重相当于一个<strong>小中心点</strong>，大致可以看出聚类的效果如何。但是对于高维数据，通过可视化方法查看聚类效果就比较差了，并且为了后续的分析处理，这里将数据集150个样本点 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>a</mi><mi>p</mi></mrow><annotation encoding="application/x-tex">map</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">p</span></span></span></span> 到隐藏层的 64 个神经元上。【其实这个过程就是机器学习中的<code>predict</code>，matlab里面称为<code>evaluate</code>】</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">y = net(x); # 直接可以evaluate 出 output，默认输出混淆矩阵</span><br><span class="line">cluster_index = vec2ind(y); # 将混淆矩阵转化为向量</span><br></pre></td></tr></table></figure>
<p>还可以通过在命令窗下输入<code>net</code>查看其余的<code>method</code>方法。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">#   methods:</span><br><span class="line">#            adapt: Learn while in continuous use</span><br><span class="line">#        configure: Configure inputs &amp; outputs</span><br><span class="line">#           gensim: Generate Simulink model</span><br><span class="line">#             init: Initialize weights &amp; biases</span><br><span class="line">#          perform: Calculate performance</span><br><span class="line">#              sim: Evaluate network outputs given inputs</span><br><span class="line">#            train: Train network with examples</span><br><span class="line">#             view: View diagram</span><br><span class="line">#      unconfigure: Unconfigure inputs &amp; outputs</span><br><span class="line">#</span><br><span class="line">#   evaluate:       outputs = net(inputs)</span><br></pre></td></tr></table></figure>
<h3 id="4可视化结果"><a class="markdownIt-Anchor" href="#4可视化结果"></a> 4.可视化结果</h3>
<p>可以画出SOM的Topology图</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">plotsomtop(net)</span><br></pre></td></tr></table></figure>
<p>还可以画出每个神经元上赢得的样本个数</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">plotsomhits(net,x)</span><br></pre></td></tr></table></figure>
<p>上面这张图反映了样本对初始六角网格的影响，但是最终的结果还是网格和特征之间的连接权重决定的。</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">plotsomplanes(net)</span><br></pre></td></tr></table></figure>
<img style="zoom:80%;" data-src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/20200216133229.png" class="lozad">
<p>颜色越深说明权重越大，因为SOM中权重和input基本上可以看作是一个东西，因为计算的就是dist距离最小的那个值作为激活权重。比如 weights 1图中的颜色越重，说明聚类中心在x1这个维度中的值越大。</p>
<h1 id="代码总结"><a class="markdownIt-Anchor" href="#代码总结"></a> 代码总结：</h1>
<table>
<thead>
<tr>
<th>函数</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Matlab%E7%BC%96%E7%A8%8B/">Matlab编程    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/20200217134252.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="next-post pull-full"><a href="/2020/02/17/%E9%BB%91%E9%A9%AC%E7%A8%8B%E5%BA%8F%E5%91%98--%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"><img class="next_cover lozad" data-src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/0ef5202d-e517-4415-9333-144bc2582477.gif" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>黑马程序员--聚类算法</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/01/15/Matlab编程-- 向量化技术&似然概率/" title="Matlab编程-- 向量化技术&似然概率"><img class="relatedPosts_cover lozad"data-src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/20200115235646.png"><div class="relatedPosts_title">Matlab编程-- 向量化技术&似然概率</div></a></div><div class="relatedPosts_item"><a href="/2020/02/01/Matlab编程 -- LDA实现/" title="Matlab编程 -- LDA实现"><img class="relatedPosts_cover lozad"data-src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/20200203182827.png"><div class="relatedPosts_title">Matlab编程 -- LDA实现</div></a></div><div class="relatedPosts_item"><a href="/2020/01/16/Matlab编程--EM算法/" title="Matlab编程--EM算法"><img class="relatedPosts_cover lozad"data-src="https://cdn.jsdelivr.net/gh/wangjs-jacky/testpic/img_temp/20200116162234.png"><div class="relatedPosts_title">Matlab编程--EM算法</div></a></div></div><div class="clear_both"></div></div></div></div><footer><div id="footer"><div class="copyright">&copy;2019 - 2020 By Jacky</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="http://wangjs-jacky.github.io">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换">繁</a><i class="nightshift fa fa-moon-o" id="nightshift" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function () {
  $('span.katex-display').wrap('<div class="katex-wrap"></div>')
})</script><script async src="/js/search/local-search.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="/js/nightshift.js"></script><script color="0,0,255" opacity="0.7" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN/js/canvas-nest.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script>const observer = lozad(); // lazy loads elements with default selector as '.lozad'
observer.observe();
</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>